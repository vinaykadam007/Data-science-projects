{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise - Find Customer preferences from Online Retail Store purchases\n",
    "\n",
    "The dataset is purchase history for a UK based online retail store. The dataset is available at http://archive.ics.uci.edu/ml/datasets/online+retail\n",
    "\n",
    "The dataset has over 5000 rows of retail history based on invoice number. Each row consists of invoice number and along it the item & quantity bought. The rows are grouped by invoice number. \n",
    "\n",
    "Perform association analysis over this dataset. The dataset is too large for manipulation. Do the manipulation country wise, ie segregate the data country wise and run analysis over them. \n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "### 1. Remove all the rows with invoices having a C before the number. Eg CXXXXXX, and having no invoice number. How many rows did you remove after this operation?\n",
    "### How many unique countries, items, and invoices are there in this dataset?\n",
    "### 2. Which country has the most purchases? Plot a bar graph (or a histogram) of country vs number of purchases. \n",
    "### 3. Plot a bar graph of unique items vs their total quantity bought. Which is the most sold item? List the 10 bestsellers.\n",
    "### 4. The data is not in the conventional form to pass it to the mlxtend library. We have to get the data in the format as shown below. How will you get this output? (You may have to use groupby, sum, reset_index and set_index function). Perform this operation on different panda dataframes which are obtained after filtering them by country. Show the output for France & Germany. \n",
    "### 5. In the image below, there are quantities greater than 1 in any column. Convert every value greater than 1 to 1 and rest should be the same.(i.e zero)\n",
    "### Perform association analysis and find the frequent itemsets. List them. What is the minimum support you chose? Justify. (Remove POSTAGE from the dataset before proceeding!) \n",
    "### Which itemsets have a confidence greater than 0.5 and lift greater than 1. List them in a formatted manner. \n",
    "![Online Retail Dataset](./data/online_retail.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### reading our data(may take a bit of longer time because of its size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/OnlineRetail.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your code goes below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
