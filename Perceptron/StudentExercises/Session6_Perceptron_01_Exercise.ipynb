{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Classification of Text Documents using Perceptron\n",
    "\n",
    "The fetch_20newsgroups in sklearn.datasets provides can provide us with a corpus of text documents based on category. The code in this notebook gets the datasets into required format. We have to classify documents into their appropriate category using Perceptron. \n",
    "\n",
    "For fetch_20newsgroups functions takes categories as following:  \n",
    "alt.atheism,talk.religion.misc,'comp.graphics,sci.space  \n",
    "The subset can be train or test.  \n",
    "\n",
    "### Perform the following operations:\n",
    "1. Fetch two datasets, with 2 categories. One of them is training dataset and the other will be test. Each dataset contains data and its labels. The random state should be 50\n",
    "2. Use the TF-IDF vectorizer to find term frequency of the training & testing dataset. \n",
    "3. Obtain the TF-IDF of every word in the vocaulbary of the training dataset. Find the following from that  \n",
    "The total number of words  \n",
    "The word having the lowest weight and highest weight  \n",
    "All the words having a weight between 0.00045 to 0.006.  \n",
    "4. Train your perceptron model with the transformed training dataset, and predict the output of the training dataset. Obtain the confusion matrix and classification report for the same. \n",
    "5. Perform Kfold cross validation scoring on the entire dataset(Training + Testing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism','talk.religion.misc','comp.graphics','sci.space',]\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=50,\n",
    "                                remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2 ... 1 0 2] [2 1 1 ... 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "X_test = vectorizer.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Perceptron(max_iter=20)\n",
    "model = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "obtained_y = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[193,  14,  24,  88],\n",
       "       [ 10, 340,  23,  16],\n",
       "       [ 23,  28, 314,  29],\n",
       "       [ 64,  14,  17, 156]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, obtained_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.61      0.63       319\n",
      "          1       0.86      0.87      0.87       389\n",
      "          2       0.83      0.80      0.81       394\n",
      "          3       0.54      0.62      0.58       251\n",
      "\n",
      "avg / total       0.75      0.74      0.74      1353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, obtained_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
